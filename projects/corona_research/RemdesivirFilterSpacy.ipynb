{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Corona\n",
    "## Philosophy and History of Science with Computational Means\n",
    "Prof Dr. Gerd Gra√ühoff\n",
    "### Filter dataframe, NLTP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English library\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRem=pd.read_json(\"dfRemdesivierResearchObjects.json\")[[\"title\",\"abstract\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfRem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evaluation of the efficacy and safety of intra...</td>\n",
       "      <td>BACKGROUND: Coronavirus disease 2019 (COVID-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Role of adjunctive treatment strategies in COV...</td>\n",
       "      <td>The coronavirus disease (COVID-19) pandemic ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Evaluation of the efficacy and safety of intra...   \n",
       "1  Role of adjunctive treatment strategies in COV...   \n",
       "\n",
       "                                            abstract  \n",
       "0  BACKGROUND: Coronavirus disease 2019 (COVID-19...  \n",
       "1  The coronavirus disease (COVID-19) pandemic ha...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRem.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2135"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRem=dfRem.dropna(subset=[\"abstract\"])\n",
    "len(dfRem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "suche=\"We show\"\n",
    "def filter(zeile):\n",
    "    cond=zeile[\"abstract\"].str.contains(suche,na=False)\n",
    "    return(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>In silico detection of SARS-CoV-2 specific B-c...</td>\n",
       "      <td>Abstract Rapid generation of diagnostics is pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Structure based drug discovery by virtual scre...</td>\n",
       "      <td>&amp;lt;p&amp;gt;Background&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;The curr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>Defining the Pandemic at the State Level: Sequ...</td>\n",
       "      <td>In December of 2019, a novel coronavirus, SARS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>COVID-19 research in Wikipedia</td>\n",
       "      <td>Wikipedia is one of the main sources of free k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>SARS-CoV-2 and SARS-CoV differ in their cell t...</td>\n",
       "      <td>SARS-CoV-2 is a novel coronavirus currently ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "341   In silico detection of SARS-CoV-2 specific B-c...   \n",
       "537   Structure based drug discovery by virtual scre...   \n",
       "649   Defining the Pandemic at the State Level: Sequ...   \n",
       "685                      COVID-19 research in Wikipedia   \n",
       "1542  SARS-CoV-2 and SARS-CoV differ in their cell t...   \n",
       "\n",
       "                                               abstract  \n",
       "341   Abstract Rapid generation of diagnostics is pa...  \n",
       "537   &lt;p&gt;Background&lt;/p&gt;&lt;p&gt;The curr...  \n",
       "649   In December of 2019, a novel coronavirus, SARS...  \n",
       "685   Wikipedia is one of the main sources of free k...  \n",
       "1542  SARS-CoV-2 is a novel coronavirus currently ca...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=dfRem[filter]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern maching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract Rapid generation of diagnostics is paramount to understand epidemiology and to control the spread of emerging infectious diseases such as COVID-19. Computational methods to predict serodiagnostic epitopes that are specific for the pathogen could help accelerate the development of new diagnostics. A systematic survey of 27 SARS-CoV-2 proteins was conducted to assess whether existing B-cell epitope prediction methods, combined with comprehensive mining of sequence databases and structural data, could predict whether a particular protein would be suitable for serodiagnosis. Nine of the predictions were validated with recombinant SARS-CoV-2 proteins in the ELISA format using plasma and sera from patients with SARS-CoV-2 infection, and a further 11 predictions were compared to the recent literature. Results appeared to be in agreement with 12 of the predictions, in disagreement with 3, while a further 5 were deemed inconclusive. We showed that two of our top five candidates, the N-terminal fragment of the nucleoprotein and the receptor-binding domain of the spike protein, have the highest sensitivity and specificity and signal-to-noise ratio for detecting COVID-19 sera/plasma by ELISA. Mixing the two antigens together for coating ELISA plates led to a sensitivity of 94% (N=80 samples from persons with RT-PCR confirmed SARS-CoV2 infection), and a specificity of 97.2% (N=106 control samples).'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=df.iloc[0].abstract\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract=nlp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Satz 0= Abstract Rapid generation of diagnostics is paramount to understand epidemiology and to control the spread of emerging infectious diseases such as COVID-19.\n",
      " Satz 1= Computational methods to predict serodiagnostic epitopes that are specific for the pathogen could help accelerate the development of new diagnostics.\n",
      " Satz 2= A systematic survey of 27 SARS-CoV-2 proteins was conducted to assess whether existing B-cell epitope prediction methods, combined with comprehensive mining of sequence databases and structural data, could predict whether a particular protein would be suitable for serodiagnosis.\n",
      " Satz 3= Nine of the predictions were validated with recombinant SARS-CoV-2 proteins in the ELISA format using plasma and sera from patients with SARS-CoV-2 infection, and a further 11 predictions were compared to the recent literature.\n",
      " Satz 4= Results appeared to be in agreement with 12 of the predictions, in disagreement with 3, while a further 5 were deemed inconclusive.\n",
      " Satz 5= We showed that two of our top five candidates, the N-terminal fragment of the nucleoprotein and the receptor-binding domain of the spike protein, have the highest sensitivity and specificity and signal-to-noise ratio for detecting COVID-19 sera/plasma by ELISA.\n",
      " Satz 6= Mixing the two antigens together for coating ELISA plates led to a sensitivity of 94% (N=80 samples from persons with RT-PCR confirmed SARS-CoV2 infection), and a specificity of 97.2% (N=106 control samples).\n"
     ]
    }
   ],
   "source": [
    "for i,sent in enumerate(abstract.sents):\n",
    "    print(f\" Satz {i}= {sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We showed that two of our top five candidates, the N-terminal fragment of the nucleoprotein and the receptor-binding domain of the spike protein, have the highest sensitivity and specificity and signal-to-noise ratio for detecting COVID-19 sera/plasma by ELISA.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=[s for s in abstract.sents]\n",
    "s=sentences[5].text\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We -PRON- PRON PRP nsubj Xx True True\n",
      "showed show VERB VBD ROOT xxxx True False\n",
      "that that SCONJ IN mark xxxx True True\n",
      "two two NUM CD nsubj xxx True True\n",
      "of of ADP IN prep xx True True\n",
      "our -PRON- DET PRP$ poss xxx True True\n",
      "top top ADJ JJ amod xxx True True\n",
      "five five NUM CD nummod xxxx True True\n",
      "candidates candidate NOUN NNS pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "the the DET DT det xxx True True\n",
      "N n ADJ JJ compound X True False\n",
      "- - PUNCT HYPH punct - False False\n",
      "terminal terminal NOUN NN compound xxxx True False\n",
      "fragment fragment NOUN NN appos xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "nucleoprotein nucleoprotein PROPN NNP pobj xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "the the DET DT det xxx True True\n",
      "receptor receptor NOUN NN npadvmod xxxx True False\n",
      "- - PUNCT HYPH punct - False False\n",
      "binding bind VERB VBG amod xxxx True False\n",
      "domain domain NOUN NN conj xxxx True False\n",
      "of of ADP IN prep xx True True\n",
      "the the DET DT det xxx True True\n",
      "spike spike NOUN NN compound xxxx True False\n",
      "protein protein NOUN NN pobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "have have AUX VBP ccomp xxxx True True\n",
      "the the DET DT det xxx True True\n",
      "highest high ADJ JJS amod xxxx True False\n",
      "sensitivity sensitivity NOUN NN dobj xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "specificity specificity NOUN NN conj xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "signal signal NOUN NN nmod xxxx True False\n",
      "- - PUNCT HYPH punct - False False\n",
      "to to ADP IN prep xx True True\n",
      "- - PUNCT HYPH punct - False False\n",
      "noise noise NOUN NN pobj xxxx True False\n",
      "ratio ratio NOUN NN conj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "detecting detect VERB VBG pcomp xxxx True False\n",
      "COVID-19 covid-19 ADJ JJ punct XXXX-dd False False\n",
      "sera sera NOUN NN nmod xxxx True False\n",
      "/ / SYM SYM punct / False False\n",
      "plasma plasma NOUN NN dobj xxxx True False\n",
      "by by ADP IN prep xx True True\n",
      "ELISA ELISA PROPN NNP pobj XXXX True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "# https://spacy.io/usage/linguistic-features\n",
    "doc=nlp(s)\n",
    "for token in doc:\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">We showed that \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of our top \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    five\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " candidates, the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    N\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "-terminal fragment of the nucleoprotein and the receptor-binding domain of the spike protein, have the highest sensitivity and specificity and signal-to-noise ratio for detecting COVID-19 sera/plasma by \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ELISA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern matching\n",
    "https://spacy.io/usage/rule-based-matching\n",
    "\n",
    "https://explosion.ai/demos/matcher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LOWER\":\"we\"},{'POS': 'VERB'}]\n",
    "matcher.add(\"matching\",None,pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches=matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1221037237276548748, 0, 2)]\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We showed\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{\"POS\":\"PRN\"},{\"LOWER\":\"showed\"}]\n",
    "matcher.add(\"m2\",None,pattern1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches2=matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We showed\n",
      "das Verb ist: show\n"
     ]
    }
   ],
   "source": [
    "for _, start, end in matches:\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(span.text)\n",
    "    span2=doc[end-1]\n",
    "    print(f\"das Verb ist: {span2.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showed\n"
     ]
    }
   ],
   "source": [
    "matches=matcher(abstract)\n",
    "for _,start,end in matches:\n",
    "    verb=abstract[end-1]\n",
    "    print(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "listverb=[]\n",
    "def actionverb(a):\n",
    "    abstract=nlp(a)\n",
    "    matches=matcher(abstract)\n",
    "    for _,start,end in matches:\n",
    "        verb=abstract[end-1]\n",
    "        listverb.append(verb.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['show']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actionverb(a)\n",
    "listverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2973"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRem[\"abstract\"].apply(actionverb)\n",
    "len(listverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'show': 67,\n",
       "         'provide': 72,\n",
       "         'summarize': 56,\n",
       "         'highlight': 20,\n",
       "         'analyze': 34,\n",
       "         'characterize': 8,\n",
       "         'notice': 8,\n",
       "         'identify': 110,\n",
       "         'describe': 114,\n",
       "         'report': 158,\n",
       "         'review': 92,\n",
       "         'reflect': 2,\n",
       "         'will': 80,\n",
       "         'discuss': 88,\n",
       "         'propose': 76,\n",
       "         'elucidate': 2,\n",
       "         'present': 102,\n",
       "         'prioritize': 4,\n",
       "         'conclude': 18,\n",
       "         'hypothesize': 18,\n",
       "         'develop': 26,\n",
       "         'predict': 24,\n",
       "         'advocate': 6,\n",
       "         'focus': 24,\n",
       "         'estimate': 14,\n",
       "         'run': 2,\n",
       "         'suggest': 40,\n",
       "         'aim': 132,\n",
       "         'search': 54,\n",
       "         'could': 10,\n",
       "         'must': 10,\n",
       "         'emphasize': 2,\n",
       "         'hope': 18,\n",
       "         'study': 14,\n",
       "         'evaluate': 38,\n",
       "         'follow': 8,\n",
       "         'assess': 18,\n",
       "         'illustrate': 2,\n",
       "         'believe': 38,\n",
       "         'use': 76,\n",
       "         'screen': 22,\n",
       "         'find': 130,\n",
       "         'discover': 18,\n",
       "         'perform': 66,\n",
       "         'may': 8,\n",
       "         'simulate': 2,\n",
       "         'recommend': 20,\n",
       "         'take': 2,\n",
       "         'include': 58,\n",
       "         'know': 12,\n",
       "         'consider': 22,\n",
       "         'analyse': 12,\n",
       "         'need': 20,\n",
       "         'should': 6,\n",
       "         'proceed': 2,\n",
       "         'enrol': 6,\n",
       "         'apply': 20,\n",
       "         'conduct': 86,\n",
       "         'ask': 2,\n",
       "         'outline': 12,\n",
       "         'contend': 2,\n",
       "         'encourage': 4,\n",
       "         'examine': 32,\n",
       "         'compare': 38,\n",
       "         'establish': 6,\n",
       "         'succeed': 2,\n",
       "         'plan': 6,\n",
       "         'create': 4,\n",
       "         'read': 6,\n",
       "         'appreciate': 2,\n",
       "         'construct': 10,\n",
       "         'divide': 8,\n",
       "         'investigate': 22,\n",
       "         'explore': 18,\n",
       "         'exclude': 8,\n",
       "         'pool': 4,\n",
       "         'introduce': 8,\n",
       "         'confirm': 2,\n",
       "         'carry': 10,\n",
       "         'assume': 4,\n",
       "         'observe': 32,\n",
       "         'speculate': 6,\n",
       "         'reanalyze': 2,\n",
       "         'can': 18,\n",
       "         'collect': 26,\n",
       "         'design': 20,\n",
       "         'determine': 10,\n",
       "         'detect': 4,\n",
       "         'denote': 2,\n",
       "         'overview': 2,\n",
       "         'dock': 10,\n",
       "         'address': 6,\n",
       "         'seek': 16,\n",
       "         'found10': 2,\n",
       "         'offer': 2,\n",
       "         'look': 6,\n",
       "         'define': 2,\n",
       "         'call': 10,\n",
       "         'await': 2,\n",
       "         'obtain': 16,\n",
       "         'refer': 2,\n",
       "         'shed': 2,\n",
       "         'build': 6,\n",
       "         'require': 2,\n",
       "         'map': 2,\n",
       "         'combine': 2,\n",
       "         'would': 10,\n",
       "         'express': 2,\n",
       "         'submit': 2,\n",
       "         'administrate': 2,\n",
       "         'undertake': 4,\n",
       "         'identifid': 2,\n",
       "         'employ': 10,\n",
       "         'rate': 4,\n",
       "         'extract': 10,\n",
       "         'anticipate': 8,\n",
       "         'download': 2,\n",
       "         'specify': 6,\n",
       "         'plot': 2,\n",
       "         'urge': 4,\n",
       "         'argue': 14,\n",
       "         'sequence': 4,\n",
       "         'generate': 6,\n",
       "         'select': 20,\n",
       "         'learn': 2,\n",
       "         'administer': 2,\n",
       "         'start': 6,\n",
       "         'keep': 2,\n",
       "         'increase': 4,\n",
       "         'allow': 2,\n",
       "         'ease': 2,\n",
       "         'challenge': 2,\n",
       "         'prioritise': 2,\n",
       "         'rank': 2,\n",
       "         'demonstrate': 20,\n",
       "         'set': 2,\n",
       "         'come': 2,\n",
       "         'advise': 2,\n",
       "         'disagree': 2,\n",
       "         'rely': 2,\n",
       "         'frame': 2,\n",
       "         'test': 12,\n",
       "         'adapt': 2,\n",
       "         'mention': 2,\n",
       "         'synthesize': 8,\n",
       "         'advance': 2,\n",
       "         'approach': 2,\n",
       "         'think': 6,\n",
       "         'summarise': 6,\n",
       "         'try': 2,\n",
       "         'scrutinise': 2,\n",
       "         'make': 12,\n",
       "         'note': 8,\n",
       "         'form': 2,\n",
       "         'calculate': 4,\n",
       "         'interpret': 2,\n",
       "         'extend': 2,\n",
       "         'characterise': 2,\n",
       "         'wait': 2,\n",
       "         'deploy': 2,\n",
       "         'utilize': 2,\n",
       "         'suspect': 2,\n",
       "         'engineer': 4,\n",
       "         'base': 2,\n",
       "         'transfecte': 2,\n",
       "         'model': 6,\n",
       "         'intend': 4,\n",
       "         'underline': 2,\n",
       "         'reopen': 2,\n",
       "         'profile': 2,\n",
       "         'risk': 2,\n",
       "         'stress': 2,\n",
       "         'decide': 4,\n",
       "         'co': 2,\n",
       "         'systematize': 2,\n",
       "         'enter': 2,\n",
       "         'comment': 2,\n",
       "         'choose': 4,\n",
       "         'solve': 4,\n",
       "         'evidence': 2,\n",
       "         'share': 2,\n",
       "         'detail': 2,\n",
       "         'clone': 2,\n",
       "         'see': 2,\n",
       "         'abstract': 4,\n",
       "         'expect': 2,\n",
       "         'manage': 4,\n",
       "         'live': 2,\n",
       "         'initiate': 2,\n",
       "         'assay': 2,\n",
       "         'showcase': 2,\n",
       "         'reason': 2,\n",
       "         'isolate': 2,\n",
       "         'herein': 2,\n",
       "         'pretreate': 2,\n",
       "         'tend': 2,\n",
       "         'refit': 2,\n",
       "         'prepare': 4,\n",
       "         'scan': 2,\n",
       "         'declare': 2,\n",
       "         'waste': 2,\n",
       "         'explain': 2,\n",
       "         'draw': 2})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(listverb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
