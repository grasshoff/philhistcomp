{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Nurse hate thread\" - The pandemic's female Other "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrape_resultat import nurse_text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(nurse_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe from list\n",
    "lst_col = 'comments'\n",
    "\n",
    "alle = pd.DataFrame({\n",
    "      col:np.repeat(df[col].values, df[lst_col].str.len())\n",
    "      for col in df.columns.drop(lst_col)}\n",
    "    ).assign(**{lst_col:np.concatenate(df[lst_col].values)})[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alle['number'] = alle[\"comments\"].str.extract(\"(\\d{9})\", expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alle['comments'] = [re.sub('(>{0,2}\\d{9}>{0,2})', ' ', i) for i in alle.comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alle['comments'] = [i.replace('∖n ', ' ').replace('∖n', ' ') for i in alle.comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NURSE HEROS</td>\n",
       "      <td>\\n                    Did everyone just sudden...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>* QUESTION * Do you agree with this nurse, to ...</td>\n",
       "      <td>\\n                    /pol/ : do you agree wit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>* QUESTION * Do you agree with this nurse, to ...</td>\n",
       "      <td>why does she dislike the white areas of Georg...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>* QUESTION * Do you agree with this nurse, to ...</td>\n",
       "      <td>As a Nurse, shouldn't she be trying to provid...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>* QUESTION * Do you agree with this nurse, to ...</td>\n",
       "      <td>Summa Cum Laude and she still can't speak pro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10209</th>\n",
       "      <td>Nurse in Wuhan states around 90,000 people are...</td>\n",
       "      <td></td>\n",
       "      <td>240820374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>Nurse in Wuhan states around 90,000 people are...</td>\n",
       "      <td>Good.</td>\n",
       "      <td>240820374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>Nurse in Wuhan states around 90,000 people are...</td>\n",
       "      <td>Nice larp. Fake and gay.</td>\n",
       "      <td>240820374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10212</th>\n",
       "      <td>Nurse in Wuhan states around 90,000 people are...</td>\n",
       "      <td>You have a sticky, learn to use the catalog</td>\n",
       "      <td>240820374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10213</th>\n",
       "      <td>Nurse in Wuhan states around 90,000 people are...</td>\n",
       "      <td>filmed in a studio in taiwan</td>\n",
       "      <td>240820374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10214 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                            NURSE HEROS   \n",
       "1      * QUESTION * Do you agree with this nurse, to ...   \n",
       "2      * QUESTION * Do you agree with this nurse, to ...   \n",
       "3      * QUESTION * Do you agree with this nurse, to ...   \n",
       "4      * QUESTION * Do you agree with this nurse, to ...   \n",
       "...                                                  ...   \n",
       "10209  Nurse in Wuhan states around 90,000 people are...   \n",
       "10210  Nurse in Wuhan states around 90,000 people are...   \n",
       "10211  Nurse in Wuhan states around 90,000 people are...   \n",
       "10212  Nurse in Wuhan states around 90,000 people are...   \n",
       "10213  Nurse in Wuhan states around 90,000 people are...   \n",
       "\n",
       "                                                comments     number  \n",
       "0      \\n                    Did everyone just sudden...        NaN  \n",
       "1      \\n                    /pol/ : do you agree wit...        NaN  \n",
       "2       why does she dislike the white areas of Georg...        NaN  \n",
       "3       As a Nurse, shouldn't she be trying to provid...        NaN  \n",
       "4       Summa Cum Laude and she still can't speak pro...        NaN  \n",
       "...                                                  ...        ...  \n",
       "10209                                                     240820374  \n",
       "10210                                             Good.   240820374  \n",
       "10211                          Nice larp. Fake and gay.   240820374  \n",
       "10212       You have a sticky, learn to use the catalog   240820374  \n",
       "10213                      filmed in a studio in taiwan   240820374  \n",
       "\n",
       "[10214 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nurse_sample = nlp(alle ['comments'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nurse_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SPACE   \n",
      "As SCONJ prep as\n",
      "a DET det a\n",
      "Nurse PROPN pobj Nurse\n",
      ", PUNCT punct ,\n",
      "should VERB aux should\n",
      "n't PART neg not\n",
      "she PRON nsubj -PRON-\n",
      "be AUX aux be\n",
      "trying VERB ROOT try\n",
      "to PART aux to\n",
      "provide VERB xcomp provide\n",
      "medical ADJ amod medical\n",
      "care NOUN dobj care\n",
      "and CCONJ cc and\n",
      "prevent VERB conj prevent\n",
      "physical ADJ amod physical\n",
      "harm NOUN dobj harm\n",
      "to ADP dative to\n",
      "folks NOUN pobj folk\n",
      "... PUNCT punct ...\n",
      "not PART neg not\n",
      "to PART aux to\n",
      "be AUX aux be\n",
      "encouraging VERB xcomp encourage\n",
      "it PRON dobj -PRON-\n",
      "? PUNCT punct ?\n",
      "? PUNCT punct ?\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_, token.dep_, token.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
