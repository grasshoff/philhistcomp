<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Text - Seminar SS 2020 Comp.Phil.Hist.Science</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  <link href="../../stylesheets/extra.css" rel="stylesheet" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Text";
    var mkdocs_page_input_path = "project_disagreement/hcq_expressing_disagreement_in_abstracts.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Seminar SS 2020 Comp.Phil.Hist.Science</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <p class="caption"><span class="caption-text">Projekte</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="#">Aztec Butterflies</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../aztec_classification_of_butterflies/FlorentineCodexButterflies/">Text</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../aztec_classification_of_butterflies/TheButterfliesOfTheFlorentineCodex/">Notebook</a>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">NYC benches</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../citybenches_nyc/city_benches_nyc/">Text</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../citybenches_nyc/01dataimport/">Notebook1</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../citybenches_nyc/02geocoding/">Notebook2</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../citybenches_nyc/03distancecalc/">Notebook3</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../citybenches_nyc/04shortestdist/">Notebook4</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../citybenches_nyc/05presentation/">Notebook5</a>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">Nurse Hate Thread</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../nurse_hate_thread/Zwischenbericht/">Text</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../nurse_hate_thread/NurseHate/">Notebook</a>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="#">Project Disagreement</a>
    <ul class="current">
                <li class="toctree-l2 current"><a class="reference internal current" href="./">Text</a>
    <ul class="current">
    <li class="toctree-l3"><a class="reference internal" href="#prof-dr-gerd-grahoff">PROF. DR. GERD GRAßHOFF</a>
    </li>
    </ul>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../disagreement_abstracts/">Notebook</a>
                </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="#">Water Security</a>
    <ul>
                <li class="toctree-l2"><a class="reference internal" href="../../water_security/text/">Text</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../water_security/Comparison_water_%28in%29security_based_on_noun_chunks/">Notebook1</a>
                </li>
                <li class="toctree-l2"><a class="reference internal" href="../../water_security/Notebook-Spacy/">Notebook2</a>
                </li>
    </ul>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Seminar SS 2020 Comp.Phil.Hist.Science</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Project Disagreement &raquo;</li>
        
      
        
          <li>Projekte &raquo;</li>
        
      
    
    <li>Text</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h4 id="philosophy-and-history-of-science-with-computational-means">PHILOSOPHY AND HISTORY OF SCIENCE WITH COMPUTATIONAL MEANS</h4>
<h5 id="prof-dr-gerd-grahoff">PROF. DR. GERD GRAßHOFF</h5>
<h1 id="expressing-disagreement-in-abstracts">Expressing Disagreement in Abstracts</h1>
<h3 id="a-reflection-on-scientific-articles-about-hydroxychloroquine-hcqcholorquine-cq-as-a-treatment-for-covid-19">A Reflection on Scientific Articles about Hydroxychloroquine (HCQ)/Cholorquine (CQ) as a Treatment for COVID-19</h3>
<h2 id="background">Background</h2>
<p>Disagreement is a subject of philosophical investigation. As a fist approximation you can characterize disagreement as follows: Disagreement is directed towards some assertion $s$. You can have different doxastic attitudes towards $s$. You can judge that $s$ is true; you can judge that $s$ is false; or you can suspend judgment. Two individuals disagree if they have different doxastic attitudes with regard to $s$. (For a introduction see: <a href="https://plato.stanford.edu/archives/win2019/entries/disagreement/">Frances/Matheson 2019</a>).</p>
<p>My project is a case study about disagreement in science. The matter of debate had to be a controversial topic in order to find disagreement expressed in scientific literature. Though the epistemic position of scientists disagreeing with each other is unknown yet it is plausible to assume that each of them is in a good epistemic position with regard to $s$. That means they are more likely to judge the truth value of $s$ correctly than to be mistaken. Since scientists are competent evaluators of $s$'s truth value it is interesting how they can judge the truth of $s$ differently.</p>
<p>The matter of debate for this project is whether Hydroxychloroquine (HCQ)/Chloroquine (CQ) is effective and safe enough to treat COVID-19. So in our case $s$ will be something like "HCQ is apt as a treatment for COVID-19". I suppose that one form in which disagreement in science occurs is that it is embedded in discourse. To trace disagreement I shall look for certain sentences that mark a position within this discourse. But I will confine myself to sentences that appear in abstracts of scientific articles.</p>
<h2 id="research-objects">Research Objects</h2>
<p><strong>Research data</strong>
With the help of the <a href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019/global-research-on-novel-coronavirus-2019-ncov/">"Global research on coronavirus disease (COVID-19)"</a>-database of the <em>World Health Organization (WHO)</em> I searched for scientific publications that are about HCQ/CQ as a possible medication for COVID-19. I found 19 articles. I used the <a href="https://app.dimensions.ai/discover/publication">DIMENSIONS</a> database to generate an Excel spread sheet with metainformation concerning these 19 publications (<code>"hcq.xlsx"</code>). By means of <code>"hcq.xlsx"</code> I could access abstracts of the 19 publications in machine readable form. (<code>"hcq.xlsx"</code> is in the directory <code>"data"</code>: <code>"data/hcq.xlsx"</code>.)</p>
<p><strong>Research objects</strong>
The research objects are sentences from abstracts that can be grouped in pairs such that a sentence pair expresses disagreement. I will call such sentences <em>disagreement sentences</em>. Pairs of disagreement sentences that express disagreement I will call <em>disagreement pairs</em>.</p>
<p><strong>Research question</strong>
What features do disagreement sentences have? How can they be assigned to disagreement pairs? 
(I have a hypothesis about what features disagreement sentences and have how they can be assigned to disagreement pairs. My aim is to write a program (notebook) that can reliably find disagreement pairs. By this I hope to gain support for the hypothesis. I will come back to that later.)</p>
<h2 id="confinements">Confinements</h2>
<p>Disagreement may be expressed in various ways. As I said I will only consider certain sentences occurring in abstracts of scientific articles. Thus expressions of disagreement are in writing. In addition I will only consider disagreement that is expressed by <em>pairs</em> of sentences. Let's look at some examples of what disagreement pairs might look like (the examples are not exhaustive):</p>
<blockquote>
<p>(PRO): "The study shows that HCQ is good as a treatment for COVID-19."</p>
<p>(CON 1): "The study shows that HCQ is bad as a treatment for COVID-19."</p>
<p>(CON 2): "Because the study is poorly done you can draw no conclusions from it about HCQ as a treatment for COVID-19."</p>
<p>(CON 3): "The study does not show that HCQ is good as a treatment for COVID-19."</p>
</blockquote>
<p>Each of the CON-sentences forms a disagreement pair together with the PRO-sentence. The program is designed to only find disagreement pairs of the form (PRO, CON 3). Furthermore the program will only work for sentences in English.</p>
<h2 id="the-basic-idea">The Basic Idea</h2>
<p>I assume disagreement sentences to have a certain structure. They express a relation between some kind of evidence and a statement $s$. I call that relation <em>SUPPORT</em>. (I suppose SUPPORT is logically a relation of the metalanguage. I think of it being similar to the relation of deducibility that may hold between a set of formulas and some single formula.) In disagreement sentences there are certain verbs that mark SUPPORT. I will call such verbs <em>SUPPORT-verbs</em>. Then there are linguistic expressions I'll call <em>EVIDENCE-nouns</em>.  They refer to evidence of some type, processes resulting in evidence or scientists/scientific institutions that produce such evidence. Disagreement sentences can be affirmative or negated. To illustrate this idea I give the following table. (The sentences are real examples from the abstracts.)
| Sentence type | Noun (EVID/SCI) | Negation (NEG) | Verb (SUPP) | Statement (Span)                                             |
| ------------- | --------------- | -------------- | ----------- | ------------------------------------------------------------ |
| PRO           | <code>The findings</code>  |                | <code>support</code>   | <code>the hypothesis that these drugs have efficacy in the treatment of COVID-19</code> |
| CON           | <code>These results</code> | <code>[do] not</code>     | <code>support</code>   | <code>the use of HCQ in patients hospitalised for documented SARS-CoV-2-positive hypoxic pneumonia</code> |</p>
<p>In case there is a SUPPORT-verb and an EVIDENCE-noun in a sentence the computer ought predict it as being a disagreement sentence. Chances are that it is one. Pairing an affirmative disagreement sentence (one without a negation expression) with a negated disagreement sentence will constitute a disagreement pair.</p>
<p>But not all pairs of affirmative and negated disagreement sentences will make a disagreement pair. An example:</p>
<blockquote>
<p>(a) "The study shows that HCQ is effective against COVID-19"</p>
<p>(b) "The study does not show that HCQ is effective against COVID-19"</p>
<p>(c) "The study shows that climate change is caused by humans"</p>
<p>(b) "The study does not show that HCQ is effective against COVID-19"</p>
</blockquote>
<p>The sentence pair (a, b) is a disagreement pair whereas the pair (c, b) is not. This is because (a) and (b) are about the same subject and (c) and (b) are about different topics. Disagreement pairs consists of sentences that are about the same topic; one sentence is affirmative and the other is negated. To let the program decide whether two sentences are about the same topic I will make use of <code>spacy</code>'s functionality to compute the similarity of linguistic objects. The similarity can be computed for the whole sentence (or document) (<em>Doc similarity</em>); or it can be computed for parts of the sentence (<em>Span similarity</em>). I take as the Span the part of the sentence which expresses its topic. The Span as understood here points to the statement of the sentence ($s$). $s$ is that what is supported by some kind of evidence. I assume that the Span is the part of the sentence that comes behind the SUPPORT-verb. (This is reflected in the table above.) As you can see from the table below the Span similarity is higher for similar topics and lower for different topics — as compared to Doc similarity:</p>
<table>
<thead>
<tr>
<th>Sentence pair</th>
<th>Doc similarity</th>
<th>Span similarity</th>
<th>Spans of sentence pair</th>
</tr>
</thead>
<tbody>
<tr>
<td>(a) "The study shows that HCQ is effective against COVID-19" &amp; (b) "The study does not show that HCQ is effective against COVID-19"</td>
<td>0.98</td>
<td>1.0</td>
<td>(Span a) "that HCQ is effective against COVID-19" &amp; (Span b) "that HCQ is effective against COVID-19"</td>
</tr>
<tr>
<td>(c) "The study shows that climate change is caused by humans" &amp; (b) "The study does not show that HCQ is effective against COVID-19"</td>
<td>0.89</td>
<td>0.77</td>
<td>(Span c) "that climate change is caused by humans" &amp; (Span b) "that HCQ is effective against COVID-19"</td>
</tr>
</tbody>
</table>
<p>For this project I will assume that Span similarity yields more reliable results than Doc similarity in determining the similarity of topic for two sentences. You could set a threshold for Span similarity, say 0.85. If the similarity for a pair of sentences is as high or higher as this threshold it ought to count being about the same topic. So in this case the sentence pair (a, b) has a Span similarity which is greater than 0.85 (1.0 &gt; 0,85). Thus it counts as being about the same topic. And since (a) is affirmative and (b) is negated (a, b) is a disagreement pair. The pair (c, b) has a Span similarity below the threshold and therefore it does not count as a disagreement pair. I may now sum up the foregoing remarks in a hypothesis:</p>
<p><strong>Hypothesis</strong>: Disagreement sentences express a relation that holds or does not hold between some kind of evidence and a statement (i. e. that evidence supports/does not support some statement). That means disagreement sentences contain expressions referring to evidence and to the SUPPORT-relation. Furthermore disagreement pairs consists of one affirmative and one negated sentence that are about a similar topic (i. e. they show a certain degree (at least) of Span similarity). </p>
<h2 id="implementation-the-notebook">Implementation: the Notebook</h2>
<p>The task is to write a program such that the computer finds disagreement pairs from abstracts of scientific articles. (I follow a rule based approach, not one that involves machine learning.) In short, the following steps are taken: (i) get abstracts of scientific articles in a form that can be processed by the computer; (ii) divide abstracts into single sentences; (iii) filter disagreement sentences from the whole collection of sentences; (iv) label entities in disagreement sentences; (v) separate (entity labeled) disagreement sentences into two groups: affirmative sentences and negated sentences; (vi) make pairs of disagreement sentences with one affirmative and one negated sentence; (vii) determine Span similarity for each pair based on this distinguish disagreement pairs from non disagreement pairs.</p>
<ul>
<li>The first step was to get the abstracts of scientific articles in a form that the computer could read and process. I assessed the abstracts, prepared them and stored the results in the json-file <code>"HCQ_clean_abstracts.json"</code> (<code>"data/HCQ_clean_abstracts.json"</code>). This preparatory work was done in the additional notebook <code>"hcq_1_clean_abstracts.ipynb"</code>. (See <a href="additional_notebooks/hcq_1_clean_abstracts.md">hcq_1_clean_abstracts.md</a>; all additional notebooks together with commenting markdown-files can be found in the directory <code>"additional_notebooks"</code>.)</li>
</ul>
<p>The other main steps are executed in the  notebook<code>"hcq_expressing_disagreement_in_abstracts.ipynb"</code>: </p>
<ul>
<li>
<p>I loaded the the abstracts from <code>"HCQ_clean_abstracts.json"</code> into the <strong><code>dataframe</code></strong> <code>abstract_df</code>. There is the title of publication and an identifier assigned to each abstract. (Section 2 in the notebook; for more information see: <a href="additional_notebooks/hcq_2_sentences.md">hcq_2_sentences.md</a>.)</p>
</li>
<li>
<p>Each abstract is divided into its sentences. I stored the sentences in another dataframe called <code>sentences_df</code>. Each sentence has a unique identifier and there is also the title of publication added from which the sentence was taken — in case these informations are needed (see <a href="additional_notebooks/hcq_2_sentences.md">hcq_2_sentences.md</a>). I take the sentences from column <code>"sentence"</code> and convert them into <strong><code>Doc</code></strong>-objects which I store in the <strong><code>list</code></strong> <code>doc_list</code>.  Our sentence collection encompasses 216 sentences.(Section 3)</p>
</li>
<li>
<p>We are now going to filter the sentences in <code>doc_list</code>. In order to do that we will use <code>spacy</code>'s <strong><code>Matcher</code></strong>. First we will filter the sentences by occurrence of SUPPORT-verbs. We are searching for particular verbs that are mostly the root of a sentence. Sometimes they are not the root but what is called in <code>spacy</code> an "open clausal complement" (<code>"xcomp"</code>). Thus the patterns for the Matcher have the following general forms:</p>
</li>
</ul>
<p><code>python
  [{"POS": "VERB", "DEP": "ROOT", "LEMMA": {"IN": verbs}}]
  [{"POS": "VERB", "DEP": "xcomp", "LEMMA": {"IN": verbs}}]</code></p>
<p>I have manually selected some verbs that in my view indicate the relation SUPPORT (for more information see: <a href="additional_notebooks/hcq_3_verb_filter.md">hcq_3_verb_filter.md</a>). The verbs in their basic form (<em>lemma</em>) are: "confirm", "reveal", "show", "suggest" and "support". The filtered sentences are stored in the list <code>verb_filtered_sentences</code>. (Subsection 4.1)</p>
<ul>
<li>We will further filter the remaining sentences in <code>verb_filtered_sentences</code> — this time by occurrence of EVIDENCE-nouns. These are particular nouns (including the pronoun "we") that most of the time serve as the nominal subject (<code>"nsubj"</code>) of a sentence (sometimes as an object (<code>"pobj"</code>). The Matcher searches with the general patterns:</li>
</ul>
<p><code>python
  [{"POS": "NOUN", "DEP": "nsubj", "LEMMA": noun/pronoun}]
  [{"POS": "NOUN", "DEP": "pobj", "LEMMA": noun}]</code></p>
<p>I manually selected the nouns (for more information see: <a href="additional_notebooks/hcq_4_noun_filter.md">hcq_4_noun_filter.md</a>). The nouns/pronouns are in the lemma form: "analysis", "evidence", "finding", "result", "survey", "trial" and "we". The further filtered sentences (datatype <strong><code>string</code></strong>) are stored in the list <code>noun_filtered_sentences</code>. From 216 sentences in our original collection 11 remained after filtering by SUPPORT-verbs and nine remained after filtering by EVIDENCE-nouns. (Subsection 4.2)</p>
<p>I have tested a few different filters to assess which works best. The combination of filtering sentences by SUPPORT-verbs <strong>and</strong> by EVIDENCE-nouns yielded the best results: Out of 216 sentences 211 are predicted correctly. Only 64 % of disagreement sentences are found. But if the computer predicts a sentence as being a disagreement sentence you can be sure that this is correct. (For information on evaluation of filters see: <a href="additional_notebooks/hcq_2_sentences.md">hcq_2_sentences.md</a>, <a href="additional_notebooks/hcq_3_verb_filter.md">hcq_3_verb_filter.md</a>, <a href="additional_notebooks/hcq_4_noun_filter.md">hcq_4_noun_filter.md</a>.)</p>
<ul>
<li>
<p>Then I define entities that shall be labeled if occurring in a sentence: SUPPORT (<strong><code>SUPP</code></strong>); evidence, processes resulting in evidence (<strong><code>EVID</code></strong>) or scientists/scientific institutions producing such evidence (<strong><code>SCI</code></strong>); and negations (<strong><code>NEG</code></strong>). To label entities I have to process the sentences in <code>noun_filtered_sentences</code>. The resulting list of sentences (Doc-objects) is called <code>disagreement_sentences</code>. (Section 5; for more information see: <a href="additional_notebooks/hcq_5_entity_labels.md">hcq_5_entity_labels.md</a>.)</p>
</li>
<li>
<p>The sentences in <code>disagreement_sentences</code> are divided into affirmative sentences and negated sentences. The affirmative sentences I store in <code>sents</code> and the negated sentences I store in <code>negated_sents</code>. (Subsection 6.1)</p>
</li>
<li>
<p>Sentences from <code>sents</code> and <code>negated_sents</code> are paired. For each pair consisting of an affirmative and one negated sentence: The Spans after the SUPPORT-verb are taken and the Span similarity is computed. If the similarity is at least 0.83 the pair is stored in <code>disagreementPairs</code>. This list contains all found disagreement pairs. (Subsection 6.2)</p>
</li>
</ul>
<p>I have evaluated several similarity thresholds to find the one for which most disagreement pairs are predicted correctly. A threshold of 0.83 yielded the best results. 13 sentence pairs out of 20 are predicted correctly. The computer will find 75 % of all disagreement pairs. If a pair is predicted as being a disagreement pair this prediction is correct in 69 % of cases. (For more information see: <a href="additional_notebooks/hcq_6_disagreement_pairs.md">hcq_6_disagreement_pairs.md</a>.)</p>
<h2 id="concluding-remarks">Concluding Remarks</h2>
<p>You can see the disagreement pairs at the end of Subsection 6.2; labeled entities are highlighted. The program forms disagreement pairs and many of them seem to be correct. But the program still has flaws. To name only the most important ones:</p>
<ul>
<li>The assumption that disagreement pairs show a higher Span similarity could not be confirmed. The average Span similarity of all considered sentence pairs is about 0.8331. The average Span similarity of sentences that I take to be disagreement pairs is very slightly higher: it is about 0.8332. With a value of about 0.8329 the average Span similarity of non disagreement pairs is only very slightly below the average Span similarity of all pairs. You could see it as pointing out to a trend but there is hardly any difference. What is more is that one disagreement pair shows a Span similarity of about 0.69 whereas a non disagreement pair shows as Span similarity of almost 0.89. (<a href="additional_notebooks/hcq_6_disagreement_pairs.md">hcq_6_disagreement_pairs.md</a>)</li>
</ul>
<p>I still believe, the assumption that disagreement pairs are about the same topic and non disagreement pairs are not, is correct. But there has to be a better way to assess topic similarity than by Span similarity.</p>
<ul>
<li>One sentence was correctly categorized as a negated disagreement sentence, but I think it was by mere accident. The negation did not negate the SUPPORT-verb but another verb in the "topic Span".</li>
</ul>
<hr />
<p>Frances, Bryan/Matheson, Jonathan (2019): "Disagreement", in: Zalta, Edward N. (Hrsg.): <em>The Stanford Encyclopedia of Philosophy</em> (Winter 2019 Edition), URL=<a href="https://plato.stanford.edu/archives/win2019/entries/disagreement/">https://plato.stanford.edu/archives/win2019/entries/disagreement/</a>.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../disagreement_abstracts/" class="btn btn-neutral float-right" title="Notebook">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../../nurse_hate_thread/NurseHate/" class="btn btn-neutral" title="Notebook"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../../nurse_hate_thread/NurseHate/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../disagreement_abstracts/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
