# Background

The use of agent-based models (ABMs) for the study of economic behaviour is an exciting but relatively unexplored field. A recent paper by Lussange, Johann, et al. [1] outlines the possibilities and challenges facing the field. In particular, they identify machine learning as an area of major impact on ABMs.

The biggest challenge and the source of most criticism for ABMs, is establishing a mathematically sound link between the model and the empirical data. For this reason, Lussange, Johann, et al. stress the need for cross-market validation, testing for the simulation of established stylistic facts (facts that have been reasonably shown to hold for all markets), and the use of a meta-algorithm for calibration, instead of calibrating by hand, as crucial for the validation of ABMs.

Such a rigorous approach is unfortunately far beyond the scope or possibilities of this project. In the next section, I outline my much simpler approach to the problem and try to justify why doing away with the statistical rigour, can still produce philosophically interesting results.

# Outline

I will build a multi-agent Reinforcement Learning model of trading, implemented with Q-learning [2]. At each time step, an agent can put a good for sale for a certain price (a certain amount of the other good) or buy one of the goods put for sale.

This model is not robust enough to simulate the stylistic facts outlined by Lussange, Johann, et al. - not to mention simulating more than one of them. For this reason, I've settled to use the much simpler "Mean Reversion" indicator - the assumption that prices tend to move to their historical average. This doesn't hold with such consistency as the indicators outlined by Lussange, Johann, et al., but it generally holds for indexes over relatively large periods, which is the only data I will look at. The "Mean Reversion" indicator is also mathematically much simpler than the ones in Lussange, Johann, et al. and easier to check for in real-world data, as well as in the data generated by the model.

For data, I will use the S&P 500, excluding data from the last 40 or 50 years. I've chosen not to include modern data, as modern High-Frequency trading and the extensive use of AI algorithms make modern financial markets extremely difficult to model. I don't know whether this matters for an indicator like "Mean Reversion", but the limitation to use only old data will certainly simplify the matters.

I hypothesize that this simple model will exhibit a similar "Mean Reversion" as real-world indexes. So What? It will be impossible to show a clear statistical correlation between the two, for reasons already outlined. Not to mention "Mean Reversion" is not a particularly robust indicator even in the real world. Such a model is useless to real Economics. But I do believe it raises an interesting philosophical question, which I would like to discuss in my final project.

The model is interesting not because Reinforcement Learning agents mimic real human behaviour, but precisely because they don't. As far as I'm aware we don't check thousands or millions of future states in our head before we make a decision. If a program that operates fundamentally differently from humans can produce the same statistical results, then what does that mean for the interpretation of these results that we create?

For example, in Finance "Mean Reversion" is often justified by: "If the price is low people expect it to go up, so they buy and the price goes up. If the price is low, people expect it to down, so they sell and the price goes down.". But AI algorithms don't expect anything, they just check a lot of possibilities - if they replicate the same results as humans trading on real-world markets, how are such interpretations of statistical facts justified?

# References

[1] Lussange, J., Belianin, A., Bourgeois-Gironde, S., & Gutkin, B. (2018). A bright future for financial agent-based models. arXiv preprint arXiv:1801.08222.
[2] R. Sutton and A. Barto, Reinforcement Learning: An Introduction (MIT Press Cambridge MA, 1998).