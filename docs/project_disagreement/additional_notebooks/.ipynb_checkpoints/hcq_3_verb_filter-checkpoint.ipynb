{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Verb Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English Library\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentences dataframe from 'HCQ_sentences.json': sentences_df\n",
    "sentences_df = pd.read_json(\"../data/HCQ_sentences.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pub.1126880632-0</td>\n",
       "      <td>COVID-19 and what pediatric rheumatologists sh...</td>\n",
       "      <td>On March 11th, 2020 the World Health Organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pub.1126880632-1</td>\n",
       "      <td>COVID-19 and what pediatric rheumatologists sh...</td>\n",
       "      <td>The infection, transmitted by 2019 novel coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pub.1126880632-2</td>\n",
       "      <td>COVID-19 and what pediatric rheumatologists sh...</td>\n",
       "      <td>Italy was early and severely involved, with a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id                                              title  \\\n",
       "0  pub.1126880632-0  COVID-19 and what pediatric rheumatologists sh...   \n",
       "1  pub.1126880632-1  COVID-19 and what pediatric rheumatologists sh...   \n",
       "2  pub.1126880632-2  COVID-19 and what pediatric rheumatologists sh...   \n",
       "\n",
       "                                            sentence  \n",
       "0  On March 11th, 2020 the World Health Organizat...  \n",
       "1  The infection, transmitted by 2019 novel coron...  \n",
       "2  Italy was early and severely involved, with a ...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Verb Filter: A first approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 An Initial Search Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Doc-object from one example sentence of 'sentences_df' (Sentence ID: pub.1126655433-13): doc\n",
    "doc = nlp(\"These results do not support the use of HCQ in patients hospitalised for documented SARS-CoV-2-positive hypoxic pneumonia.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These DET\n",
      "results NOUN\n",
      "do AUX\n",
      "not PART\n",
      "support VERB\n",
      "the DET\n",
      "use NOUN\n",
      "of ADP\n",
      "HCQ PROPN\n",
      "in ADP\n",
      "patients NOUN\n",
      "hospitalised VERB\n",
      "for ADP\n",
      "documented VERB\n",
      "SARS PROPN\n",
      "- PUNCT\n",
      "CoV-2-positive NOUN\n",
      "hypoxic ADJ\n",
      "pneumonia NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Part-of-Speech (POS) tags for tokens in 'doc'\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support', 'hospitalised', 'documented']\n"
     ]
    }
   ],
   "source": [
    "pos_verb = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"VERB\":\n",
    "        pos_verb.append(token.text)\n",
    "        \n",
    "print(pos_verb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These DET det\n",
      "results NOUN nsubj\n",
      "do AUX aux\n",
      "not PART neg\n",
      "support VERB ROOT\n",
      "the DET det\n",
      "use NOUN dobj\n",
      "of ADP prep\n",
      "HCQ PROPN pobj\n",
      "in ADP prep\n",
      "patients NOUN pobj\n",
      "hospitalised VERB acl\n",
      "for ADP prep\n",
      "documented VERB amod\n",
      "SARS PROPN nmod\n",
      "- PUNCT punct\n",
      "CoV-2-positive NOUN nmod\n",
      "hypoxic ADJ amod\n",
      "pneumonia NOUN pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Dependencies (DEP) for tokens in 'doc'\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['support']\n"
     ]
    }
   ],
   "source": [
    "pos_dep_verb = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"VERB\":\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            pos_dep_verb.append(token.text)\n",
    "        \n",
    "print(pos_dep_verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial search pattern to find SUPPORT-verbs:'initial_search_pattern'\n",
    "initial_search_pattern = [{\"POS\": \"VERB\", \"DEP\": \"ROOT\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a matcher to test 'initial_search_pattern' on 'doc': 'test_matcher'\n",
    "test_matcher = Matcher(nlp.vocab, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pattern 'initial_search_pattern' to matcher 'test_matcher'\n",
    "test_matcher.add(\"TEST_ID\", None, initial_search_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support\n"
     ]
    }
   ],
   "source": [
    "# Apply 'test_matcher' on 'doc'\n",
    "for match_id, start, end in test_matcher(doc):\n",
    "    print(doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support\n"
     ]
    }
   ],
   "source": [
    "# An alternative way to code it\n",
    "for (match_id, start, end) in test_matcher(doc):\n",
    "    print(doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detour: What does a match (=Matcher(Doc)) look like?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1961263444387358288, 4, 5)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'test_matcher' on 'doc': match\n",
    "match = test_matcher(doc)\n",
    "\n",
    "# Show 'match'\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell what type of object 'match' is\n",
    "type(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell how many items are in 'match'\n",
    "len(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1961263444387358288, 4, 5)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show first item in list 'match'\n",
    "match[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell what type of object the fist item in 'match' is\n",
    "type(match[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support\n"
     ]
    }
   ],
   "source": [
    "# Print slice of 'doc' with last two numbers in the tuple \n",
    "print(doc[4:5].text)     # start index = 4; end index = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell what type of object 'doc[4:5]' is\n",
    "type(doc[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new Doc that creates no matches with 'test_matcher': doc2\n",
    "doc2 = nlp(\"COVID-19 is a global health threat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID-19 PROPN nsubj\n",
      "is AUX ROOT\n",
      "a DET det\n",
      "global ADJ amod\n",
      "health NOUN compound\n",
      "threat NOUN attr\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Show that there is no token in 'doc2' that is both a verb and the root of the sentence\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply 'test_matcher' on 'doc2': match2\n",
    "match2 = test_matcher(doc2)\n",
    "\n",
    "# Show 'match2'\n",
    "match2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell how many items are in 'match2'\n",
    "len(match2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 List of SUPPORT-verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of sentences (Doc-object) \n",
    "# from column 'sentence' of dataframe 'sentences_df': doc_list\n",
    "doc_list = list(nlp.pipe(sentences_df[\"sentence\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[On March 11th, 2020 the World Health Organization declared COVID-19 a global pandemic., The infection, transmitted by 2019 novel coronavirus (2019-nCov), was first discovered in December 2019, in Wuhan, Hubei Province, and then rapidly spread worldwide., Italy was early and severely involved, with a critical spread of the infection and a very high number of victims., Person-to-person spread mainly occurs via respiratory droplets and contact., The median incubation period is 5 days., The spectrum of respiratory symptoms may range from mild to severe, strictly depending on the age of the patient and the underlying comorbidities., In children COVID-19 related disease is less frequent and less aggressive., In Italy 1% of positive cases are under 18 years of age, and no deaths have been recorded before 29 years of age., For patients affected by rheumatic disease, despite the concerns related to the imbalance of their immune response and the effect of immunosuppressive treatments, there are still few data to understand the real consequences of this infection., Major scientific societies have issued recommendations to help rheumatologists in caring their patients.]\n"
     ]
    }
   ],
   "source": [
    "# Print 'doc_list' (first ten items only)\n",
    "print(doc_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make matcher 'initial_search_matcher'\n",
    "initial_search_matcher = Matcher(nlp.vocab, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add pattern 'initial_search_pattern' to 'initial_search_matcher'\n",
    "initial_search_matcher.add(\"INITIAL_SEARCH_ID\", None, initial_search_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function 'match_verb_root()'\n",
    "def match_verb_root(Doc_list):\n",
    "    lemma = set()     # Make set 'lemma'\n",
    "    \n",
    "    for Doc in Doc_list:          # First loop: iterate over all Doc-objects in Doc_list\n",
    "        for match_id, start, end in initial_search_matcher(Doc):     # Second loop: iterate over all tuples in the list\n",
    "                                                                     # which is created by 'initial_search_matcher(Doc)'\n",
    "                \n",
    "            lemma.add(Doc[start:end].lemma_)                         # For Doc-object at hand: Slice it by means of start \n",
    "                                                                     # index and end index, get basic form (lemma) of\n",
    "                                                                     # token(s) in that slice and add this lemma to 'lemma'\n",
    "            \n",
    "    return sorted(list(lemma), key=str.lower)                        # Convert set 'lemma' into a list, sort items in it \n",
    "                                                                     # alphabetically and return the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_verb_lemma = match_verb_root(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add', 'adjust', 'affect', 'aim', 'allocate', 'analyze', 'appear', 'assess', 'assign', 'associate', 'base', 'become', 'bring', 'call', 'carry', 'cause', 'claim', 'comprise', 'confirm', 'consider', 'declare', 'demonstrate', 'diagnose', 'die', 'direct', 'discover', 'draw', 'drive', 'enrol', 'enter', 'evaluate', 'exclude', 'expect', 'experience', 'explore', 'face', 'find', 'focus', 'follow', 'force', 'help', 'hospitalise', 'identify', 'improve', 'include', 'increase', 'indicate', 'issue', 'know', 'launch', 'like', 'make', 'measure', 'need', 'observe', 'obtain', 'occur', 'perform', 'play', 'predispose', 'present', 'progress', 'provide', 'raise', 'range', 'receive', 'recommend', 'record', 'register', 'report', 'represent', 'require', 'result', 'reveal', 'review', 'seek', 'set', 'share', 'shorten', 'show', 'spread', 'suggest', 'support', 'transfer', 'treat', 'understand', 'use']\n"
     ]
    }
   ],
   "source": [
    "print(root_verb_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aid to help selecting verbs manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make generator form 'root_verb_lemma': verb_generator\n",
    "verb_generator = (verb for verb in root_verb_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verb_to_prove: add\n",
      "Sentences found with 'add' in it: \n",
      "----------------------------------------\n",
      "\n",
      "(0) Depending on their clinical presentation, azithromycin was added to the treatment.\n",
      "(1) Azithromycin added to hydroxychloroquine\n"
     ]
    }
   ],
   "source": [
    "# Next item of 'verb_generator': verb_to_prove\n",
    "verb_to_prove = next(verb_generator)\n",
    "\n",
    "# Show current 'verb_to_prove'\n",
    "print(f\"verb_to_prove: {verb_to_prove}\")\n",
    "\n",
    "# Make empty list: found_sentences\n",
    "found_sentences = []\n",
    "\n",
    "for doc in doc_list:     # Iterate over all Doc-objects in 'doc_list'\n",
    "    for match_id, start, end in initial_search_matcher(doc):     # Iterate over all matches (tuples) for the current Doc\n",
    "        if doc[start:end].lemma_ == verb_to_prove:               # If the lemma of the matched Span is equal to the \n",
    "                                                                 # current 'verb_to_prove':\n",
    "                \n",
    "            if doc not in found_sentences:                       # Check if the Doc is not already in 'found_sentences'\n",
    "                                                                 # if it is not:\n",
    "                found_sentences.append(doc)                      # Add the current Doc to the list 'found_sentences'\n",
    "                    \n",
    "                    \n",
    "print(f\"Sentences found with '{verb_to_prove}' in it: \")\n",
    "print(\"----------------------------------------\\n\")\n",
    "\n",
    "# Show each found Doc(sentence) with its respective index number \n",
    "for sentence_number, sentence in enumerate(found_sentences):\n",
    "    print(f\"({sentence_number}) {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_verbs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_verbs.append(verb_to_prove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(selected_verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "selected_verbs = ['reveal', 'show', 'suggest', 'support']\n",
    "```\n",
    "\n",
    "4 SUPPORT-verbs:\n",
    "* reveal\n",
    "* show\n",
    "* suggest\n",
    "* support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 A First Verb Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make matcher 'verb_matcher_1'\n",
    "verb_matcher_1 = Matcher(nlp.vocab, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make search pattern for 'verb_matcher_1': support_verbs_pattern\n",
    "support_verbs_pattern = [{\"POS\": \"VERB\", \"DEP\": \"ROOT\", \"LEMMA\": {\"IN\": ['reveal', 'show', 'suggest', 'support']}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'support_verbs_pattern' to 'verb_matcher_1'\n",
    "verb_matcher_1.add(\"VERB_ID\", None, support_verbs_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Doc-objects (sentences) in 'doc_list' and add the selected Docs to a list: verb_filtered_sentences_1\n",
    "verb_filtered_sentences_1 = [doc for doc in doc_list if len(verb_matcher_1(doc)) > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) This work was supported by the Emergent Projects of National Science and Technology (2020YFC0844500), National Natural Science Foundation of China (81970020, 81770025), National Key Research and Development Program of China (2016YFC0901104), Shanghai Municipal Key Clinical Specialty (shslczdzk02202, shslczdzk01103), National Innovative Research Team of High-level Local Universities in Shanghai, Shanghai Key Discipline for Respiratory Diseases (2017ZZ02014), National Major Scientific and Technological Special Project for Significant New Drugs Development (2017ZX09304007), Key Projects in the National Science and Technology Pillar Program during the Thirteenth Five-year Plan Period (2018ZX09206005-004, 2017ZX10202202-005-004, 2017ZX10203201-008).\n",
      "(1) This re-analysis reveals severe limitations in the methodology of this study, including ambiguous inclusion/exclusion of participant data and inconsistent analysis techniques, and yielded nonsignificant differences between control and treatment groups across any treatment days.\n",
      "(2) This systematic review and meta-analysis showed no clinical benefits regarding HCQ treatment with/without azithromycin for COVID-19 patients.\n",
      "(3) These results do not support the use of HCQ in patients hospitalised for documented SARS-CoV-2-positive hypoxic pneumonia.\n",
      "(4) Interpretation Preliminary findings suggest that the higher CQ dosage (10-day regimen) should not be recommended for COVID-19 treatment because of its potential safety hazards.\n",
      "(5) Preliminary evidence suggests potential benefit with chloroquine or hydroxychloroquine.\n",
      "(6) Current international society recommendations suggest that patients with rheumatic diseases on immunosuppressive therapy should not stop glucocorticoids during COVID-19 infection, although minimum possible doses may be used.\n",
      "(7) The findings support the hypothesis that these drugs have efficacy in the treatment of COVID-19.\n",
      "(8) Despite its small sample size, our survey shows that hydroxychloroquine treatment is significantly associated with viral load reduction/disappearance in COVID-19 patients and its effect is reinforced by azithromycin.\n",
      "(9) Chloroquine phosphate, an old drug for treatment of malaria, is shown to have apparent efficacy and acceptable safety against COVID-19 associated pneumonia in multicenter clinical trials conducted in China.\n"
     ]
    }
   ],
   "source": [
    "# Print each enumerated verb filtered sentence\n",
    "for sentence_number, sentence in enumerate(verb_filtered_sentences_1):\n",
    "    print(f\"({sentence_number}) {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in 'doc_list': 216\n",
      "Number of sentences in 'verb_filtered_sentences_1': 10\n"
     ]
    }
   ],
   "source": [
    "# Show number of item in 'doc_list'/'verb_filtered_sentences_1' using 'len()'\n",
    "print(f\"Number of sentences in 'doc_list': {len(doc_list)}\")\n",
    "print(f\"Number of sentences in 'verb_filtered_sentences_1': {len(verb_filtered_sentences_1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluation I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the following steps see:** \n",
    "Youtube: [\"Intro to NLP with spaCy (3): Detecting programming languages | Episode 3: Evaluation\"](https://youtu.be/4V0JDdohxAk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Measuring Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>On March 11th, 2020 the World Health Organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The infection, transmitted by 2019 novel coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy was early and severely involved, with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Person-to-person spread mainly occurs via resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The median incubation period is 5 days.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      0  On March 11th, 2020 the World Health Organizat...\n",
       "1      0  The infection, transmitted by 2019 novel coron...\n",
       "2      0  Italy was early and severely involved, with a ...\n",
       "3      0  Person-to-person spread mainly occurs via resp...\n",
       "4      0            The median incubation period is 5 days."
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load 'sentences_labeled.xlsx' as a dataframe: measuring_df_1\n",
    "measuring_df_1 = pd.read_excel(\"../labeling/sentences_labeled.xlsx\")\n",
    "\n",
    "# Show first 5 rows of 'measuring_df_1'\n",
    "measuring_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column that tells whether the sentence in column 'sentence' yields a match with 'verb_matcher_1': prediction\n",
    "measuring_df_1 = measuring_df_1.assign(prediction=lambda df: [len(verb_matcher_1(doc)) > 0 for doc in nlp.pipe(df[\"sentence\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>Proposals should be directed to the correspond...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>Recent publications have brought attention to ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>The scientific community should consider this ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>A recent open-label study claimed that hydroxy...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>This re-analysis reveals severe limitations in...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                           sentence  prediction\n",
       "71      0  Proposals should be directed to the correspond...       False\n",
       "72      0  Recent publications have brought attention to ...       False\n",
       "73      0  The scientific community should consider this ...       False\n",
       "74      0  A recent open-label study claimed that hydroxy...       False\n",
       "75      1  This re-analysis reveals severe limitations in...        True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows no. 71-75 of 'measuring_df_1'\n",
    "measuring_df_1.iloc[71:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column 'prediction' in such a way that booleans ('True'/'False') are turned into '1'/'0'\n",
    "measuring_df_1 = measuring_df_1.assign(prediction=lambda df: df[\"prediction\"].astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>Proposals should be directed to the correspond...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>Recent publications have brought attention to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>The scientific community should consider this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>A recent open-label study claimed that hydroxy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>This re-analysis reveals severe limitations in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                           sentence  prediction\n",
       "71      0  Proposals should be directed to the correspond...           0\n",
       "72      0  Recent publications have brought attention to ...           0\n",
       "73      0  The scientific community should consider this ...           0\n",
       "74      0  A recent open-label study claimed that hydroxy...           0\n",
       "75      1  This re-analysis reveals severe limitations in...           1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows no. 71-75 of 'measuring_df_1'\n",
    "measuring_df_1.iloc[71:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange position of columns\n",
    "measuring_df_1 = measuring_df_1[[\"sentence\", \"label\", \"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Proposals should be directed to the correspond...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Recent publications have brought attention to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>The scientific community should consider this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>A recent open-label study claimed that hydroxy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>This re-analysis reveals severe limitations in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  label  prediction\n",
       "71  Proposals should be directed to the correspond...      0           0\n",
       "72  Recent publications have brought attention to ...      0           0\n",
       "73  The scientific community should consider this ...      0           0\n",
       "74  A recent open-label study claimed that hydroxy...      0           0\n",
       "75  This re-analysis reveals severe limitations in...      1           1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measuring_df_1.iloc[71:76]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200,   2],\n",
       "       [  6,   8]], dtype=int64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make confusion matrix from 'measuring_df_1[\"label\"]' and 'measuring_df_1[\"prediction\"]'\n",
    "confusion_matrix(measuring_df_1[\"label\"], measuring_df_1[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       202\n",
      "           1       0.80      0.57      0.67        14\n",
      "\n",
      "    accuracy                           0.96       216\n",
      "   macro avg       0.89      0.78      0.82       216\n",
      "weighted avg       0.96      0.96      0.96       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make classification report from 'measuring_df_1[\"label\"]' and 'measuring_df_1[\"prediction\"]' and show it on screen\n",
    "print(classification_report(measuring_df_1[\"label\"], measuring_df_1[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Positives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = measuring_df_1.loc[measuring_df_1[\"prediction\"] == 1].loc[measuring_df_1[\"label\"] == 0, [\"sentence\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>This work was supported by the Emergent Projec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Current international society recommendations ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence\n",
       "60   This work was supported by the Emergent Projec...\n",
       "143  Current international society recommendations ..."
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) This work was supported by the Emergent Projects of National Science and Technology (2020YFC0844500), National Natural Science Foundation of China (81970020, 81770025), National Key Research and Development Program of China (2016YFC0901104), Shanghai Municipal Key Clinical Specialty (shslczdzk02202, shslczdzk01103), National Innovative Research Team of High-level Local Universities in Shanghai, Shanghai Key Discipline for Respiratory Diseases (2017ZZ02014), National Major Scientific and Technological Special Project for Significant New Drugs Development (2017ZX09304007), Key Projects in the National Science and Technology Pillar Program during the Thirteenth Five-year Plan Period (2018ZX09206005-004, 2017ZX10202202-005-004, 2017ZX10203201-008).\n",
      "(1) Current international society recommendations suggest that patients with rheumatic diseases on immunosuppressive therapy should not stop glucocorticoids during COVID-19 infection, although minimum possible doses may be used.\n"
     ]
    }
   ],
   "source": [
    "for sentence_number, sentence in enumerate(false_positives[\"sentence\"].to_list()):\n",
    "    print(f\"({sentence_number}) {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False Negatives**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = measuring_df_1.loc[measuring_df_1[\"prediction\"] == 0].loc[measuring_df_1[\"label\"] == 1, [\"sentence\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) We were unable to confirm a benefit of hydroxychloroquine or chloroquine, when used alone or with a macrolide, on in-hospital outcomes for COVID-19.\n",
      "(1) The administration of HCQ did not result in a significantly higher negative conversion probability than SOC alone in patients mainly hospitalized with persistent mild to moderate COVID-19.\n",
      "(2) Adverse events were higher in HCQ recipients than in HCQ non-recipients.\n",
      "(3) Although mortality rate was not significantly different between cases and controls, frequency of adverse effects was substantially higher in HCQ regimen group.\n",
      "(4) Use of these drugs is premature and potentially harmful\n",
      "(5) Among patients with COVID-19, the use of HCQ could significantly shorten TTCR and promote the absorption of pneumonia.\n"
     ]
    }
   ],
   "source": [
    "for sentence_number, sentence in enumerate(false_negatives[\"sentence\"].to_list()):\n",
    "    print(f\"({sentence_number}) {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Verb Filter: Refinements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Doc of the sentence we want the verb filter to find: doc3\n",
    "doc3 = nlp(\"We were unable to confirm a benefit of hydroxychloroquine or chloroquine, when used alone or with a macrolide, on in-hospital outcomes for COVID-19.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We PRON nsubj -PRON-\n",
      "were AUX ROOT be\n",
      "unable ADJ acomp unable\n",
      "to PART aux to\n",
      "confirm VERB xcomp confirm\n",
      "a DET det a\n",
      "benefit NOUN dobj benefit\n",
      "of ADP prep of\n",
      "hydroxychloroquine NOUN pobj hydroxychloroquine\n",
      "or CCONJ cc or\n",
      "chloroquine NOUN conj chloroquine\n",
      ", PUNCT punct ,\n",
      "when ADV advmod when\n",
      "used VERB advcl use\n",
      "alone ADV advmod alone\n",
      "or CCONJ cc or\n",
      "with ADP conj with\n",
      "a DET det a\n",
      "macrolide NOUN pobj macrolide\n",
      ", PUNCT punct ,\n",
      "on ADP prep on\n",
      "in ADP nmod in\n",
      "- PUNCT punct -\n",
      "hospital NOUN pobj hospital\n",
      "outcomes NOUN pobj outcome\n",
      "for ADP prep for\n",
      "COVID-19 PROPN pobj COVID-19\n",
      ". PUNCT punct .\n"
     ]
    }
   ],
   "source": [
    "# Show linguistic features of 'doc3'\n",
    "for token in doc3:\n",
    "    print(token.text, token.pos_, token.dep_, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'open clausal complement'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"xcomp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make additional search pattern: confirm_pattern\n",
    "confirm_pattern = [{\"POS\": \"VERB\", \"DEP\": \"xcomp\", \"LEMMA\": \"confirm\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new verb matcher 'verb_matcher_2'\n",
    "verb_matcher_2 = Matcher(nlp.vocab, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat search pattern for 'verb_matcher_2': support_verbs_pattern\n",
    "support_verbs_pattern = [{\"POS\": \"VERB\", \"DEP\": \"ROOT\", \"LEMMA\": {\"IN\": ['reveal', 'show', 'suggest', 'support']}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'support_verbs_pattern' and 'confirm_pattern' to 'verb_matcher_2'\n",
    "verb_matcher_2.add(\"VERB_ID\", None, support_verbs_pattern, confirm_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Doc-objects (sentences) in 'doc_list' and add the selected Docs to a list: verb_filtered_sentences_2\n",
    "verb_filtered_sentences_2 = [doc for doc in doc_list if len(verb_matcher_2(doc)) > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) We were unable to confirm a benefit of hydroxychloroquine or chloroquine, when used alone or with a macrolide, on in-hospital outcomes for COVID-19.\n",
      "(1) This work was supported by the Emergent Projects of National Science and Technology (2020YFC0844500), National Natural Science Foundation of China (81970020, 81770025), National Key Research and Development Program of China (2016YFC0901104), Shanghai Municipal Key Clinical Specialty (shslczdzk02202, shslczdzk01103), National Innovative Research Team of High-level Local Universities in Shanghai, Shanghai Key Discipline for Respiratory Diseases (2017ZZ02014), National Major Scientific and Technological Special Project for Significant New Drugs Development (2017ZX09304007), Key Projects in the National Science and Technology Pillar Program during the Thirteenth Five-year Plan Period (2018ZX09206005-004, 2017ZX10202202-005-004, 2017ZX10203201-008).\n",
      "(2) This re-analysis reveals severe limitations in the methodology of this study, including ambiguous inclusion/exclusion of participant data and inconsistent analysis techniques, and yielded nonsignificant differences between control and treatment groups across any treatment days.\n",
      "(3) This systematic review and meta-analysis showed no clinical benefits regarding HCQ treatment with/without azithromycin for COVID-19 patients.\n",
      "(4) These results do not support the use of HCQ in patients hospitalised for documented SARS-CoV-2-positive hypoxic pneumonia.\n",
      "(5) Interpretation Preliminary findings suggest that the higher CQ dosage (10-day regimen) should not be recommended for COVID-19 treatment because of its potential safety hazards.\n",
      "(6) Preliminary evidence suggests potential benefit with chloroquine or hydroxychloroquine.\n",
      "(7) Current international society recommendations suggest that patients with rheumatic diseases on immunosuppressive therapy should not stop glucocorticoids during COVID-19 infection, although minimum possible doses may be used.\n",
      "(8) The findings support the hypothesis that these drugs have efficacy in the treatment of COVID-19.\n",
      "(9) Despite its small sample size, our survey shows that hydroxychloroquine treatment is significantly associated with viral load reduction/disappearance in COVID-19 patients and its effect is reinforced by azithromycin.\n",
      "(10) Chloroquine phosphate, an old drug for treatment of malaria, is shown to have apparent efficacy and acceptable safety against COVID-19 associated pneumonia in multicenter clinical trials conducted in China.\n"
     ]
    }
   ],
   "source": [
    "# Print each enumerated verb filtered sentence\n",
    "for sentence_number, sentence in enumerate(verb_filtered_sentences_2):\n",
    "    print(f\"({sentence_number}) {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in 'doc_list': 216\n",
      "Number of sentences in 'verb_filtered_sentences_2': 11\n"
     ]
    }
   ],
   "source": [
    "# Show number of item in 'doc_list'/'verb_filtered_sentences_2' using 'len()'\n",
    "print(f\"Number of sentences in 'doc_list': {len(doc_list)}\")\n",
    "print(f\"Number of sentences in 'verb_filtered_sentences_2': {len(verb_filtered_sentences_2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Evaluation II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measuring Device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 'sentences_labeled.xlsx' as a dataframe: measuring_df_2\n",
    "measuring_df_2 = pd.read_excel(\"../labeling/sentences_labeled.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column that tells whether the sentence in column 'sentence' yields a match with 'verb_matcher_2': prediction\n",
    "measuring_df_2 = measuring_df_2.assign(prediction=lambda df: [len(verb_matcher_2(doc)) > 0 for doc in nlp.pipe(df[\"sentence\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column 'prediction' in such a way that booleans ('True'/'False') are turned into '1'/'0'\n",
    "measuring_df_2 = measuring_df_2.assign(prediction=lambda df: df[\"prediction\"].astype(np.int8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange position of columns\n",
    "measuring_df_2 = measuring_df_2[[\"sentence\", \"label\", \"prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Proposals should be directed to the correspond...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Recent publications have brought attention to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>The scientific community should consider this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>A recent open-label study claimed that hydroxy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>This re-analysis reveals severe limitations in...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  label  prediction\n",
       "71  Proposals should be directed to the correspond...      0           0\n",
       "72  Recent publications have brought attention to ...      0           0\n",
       "73  The scientific community should consider this ...      0           0\n",
       "74  A recent open-label study claimed that hydroxy...      0           0\n",
       "75  This re-analysis reveals severe limitations in...      1           1"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measuring_df_2.iloc[71:76]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200,   2],\n",
       "       [  5,   9]], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make confusion matrix from 'measuring_df_2[\"label\"]' and 'measuring_df_2[\"prediction\"]'\n",
    "confusion_matrix(measuring_df_2[\"label\"], measuring_df_2[\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       202\n",
      "           1       0.82      0.64      0.72        14\n",
      "\n",
      "    accuracy                           0.97       216\n",
      "   macro avg       0.90      0.82      0.85       216\n",
      "weighted avg       0.97      0.97      0.97       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make classification report from 'measuring_df_2[\"label\"]' and 'measuring_df_2[\"prediction\"]' and show it on screen\n",
    "print(classification_report(measuring_df_2[\"label\"], measuring_df_2[\"prediction\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
